{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理分类\n",
    "1,最大值最小值处理法_MinMaxScaler\n",
    "2,正态化处理方法_StandardScaler\n",
    "3,标准化数据处理方法_Normalizer\n",
    "4,二值处理法_Binarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "使得特征的分布是在一个给定最小值和最大值的范围内的。一般情况下是在[0,1]之间，或者是特征中绝对值最大的那个数为1，其他数以此维标准分布在[0，1]之间,使用参数transformer = MinMaxScaler(feature_range = (-1,1))中feature_range来实现0,1极值还是-1,1极值\n",
    "之所以需要将特征规模化到一定的[0,1]范围内，是为了对付那些标准差相当小的特征并且保留下稀疏数据中的0值。\n",
    "这种方法有个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。\n",
    "敲黑板，这种方法对于outlier非常敏感，因为outlier影响了max或min值，所以这种方法只适用于数据在一个范围内分布的情况\n",
    "\n",
    "实战错误:MinMaxScaler.transform_fit(x)方法没办法对一个sample进行转换, 报错,Expected 2D array, got 1D array instead:\n",
    "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
    "解决方案:\n",
    "将数据先reshape再转换X = data['交易金额'].reshape(-1,1),reshape中-1的意义参照链接,讲的是我不清楚原来数据是多少行,多少列的,我要求转换为1列,对应的reshape(2,-1)意思是将数据转换为2列,详细解释见链接\n",
    "https://blog.csdn.net/weixin_39449570/article/details/78619196\n",
    "\n",
    "关于一列数据reshape(1,-1)后,调用MinMaxScaler所有数据变为最小值的原因在于,变换是在axis = 0方向进行的,经过这样的reshape后,变为了一行数据,通过每列计算MinMaxScaler,当然变为了默认值最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('test.csv',dtype = 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1291 entries, 0 to 1290\n",
      "Data columns (total 7 columns):\n",
      "交易日期       1291 non-null object\n",
      "商户名称       1291 non-null object\n",
      "出款新生订单号    1291 non-null object\n",
      "银行开户名      1291 non-null object\n",
      "银行账户号      1291 non-null object\n",
      "银行名称       1291 non-null object\n",
      "交易金额       1291 non-null float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 70.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data['交易金额'] = data['交易金额'].astype('float')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "transformer = MinMaxScaler(feature_range = (-1,1))\n",
    "X = data['交易金额'].reshape(-1,1)\n",
    "newX = transformer.fit_transform(X)\n",
    "# newX\n",
    "# # X\n",
    "newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MinMaxScaler in module sklearn.preprocessing.data object:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Transforms features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, i.e. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : boolean, optional, default True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray, shape (n_features,)\n",
      " |      Per feature adjustment for minimum.\n",
      " |  \n",
      " |  scale_ : ndarray, shape (n_features,)\n",
      " |      Per feature relative scaling of the data.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray, shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray, shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray, shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>>\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [  1.  18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[ 0.    0.  ]\n",
      " |   [ 0.25  0.25]\n",
      " |   [ 0.5   0.5 ]\n",
      " |   [ 1.    1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[ 1.5  0. ]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  minmax_scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when `fit` is not feasible due to very large number of `n_samples`\n",
      " |      or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : Passthrough for ``Pipeline`` compatibility.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scaling features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(transformer)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
